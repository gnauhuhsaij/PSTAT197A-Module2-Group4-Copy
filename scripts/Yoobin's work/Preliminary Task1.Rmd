---
title: "Preliminary Task1"
author: "Yoobin Won"
date: "2023-11-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#### Packages
```{r}
require(tidyverse)
require(tidytext)
require(textstem)
require(rvest)
require(qdapRegex)
require(stopwords)
require(tokenizers)
library(keras)
library(tensorflow)
library(tidymodels)
library(modelr)
library(Matrix)
library(sparsesvd)
library(glmnet)

source('https://raw.githubusercontent.com/pstat197/pstat197a/main/materials/scripts/package-installs.R')

url <- 'https://raw.githubusercontent.com/pstat197/pstat197a/main/materials/activities/data/'
source(paste(url, 'projection-functions.R', sep = ''))
```


## Claims without headers

#### Functions from prediction.R
```{r, echo=FALSE}
# function to parse html and clean text
parse_fn <- function(.html){
  read_html(.html) %>%
    html_elements('p') %>%
    html_text2() %>%
    str_c(collapse = ' ') %>%
    rm_url() %>%
    rm_email() %>%
    str_remove_all('\'') %>%
    str_replace_all(paste(c('\n', 
                            '[[:punct:]]', 
                            'nbsp', 
                            '[[:digit:]]', 
                            '[[:symbol:]]'),
                          collapse = '|'), ' ') %>%
    str_replace_all("([a-z])([A-Z])", "\\1 \\2") %>%
    tolower() %>%
    str_replace_all("\\s+", " ")
}

# function to apply to claims data
parse_data <- function(.df){
  out <- .df %>%
    filter(str_detect(text_tmp, '<!')) %>%
    rowwise() %>%
    mutate(text_clean = parse_fn(text_tmp)) %>%
    unnest(text_clean) 
  return(out)
}

nlp_fn <- function(parse_data.out){
  out <- parse_data.out %>% 
    unnest_tokens(output = token, 
                  input = text_clean, 
                  token = 'words',
                  stopwords = str_remove_all(stop_words$word, 
                                             '[[:punct:]]')) %>%
    mutate(token.lem = lemmatize_words(token)) %>%
    filter(str_length(token.lem) > 2) %>%
    count(.id, bclass, token.lem, name = 'n') %>%
    bind_tf_idf(term = token.lem, 
                document = .id,
                n = n) %>%
    pivot_wider(id_cols = c('.id', 'bclass'),
                names_from = 'token.lem',
                values_from = 'tf_idf',
                values_fill = 0)
  return(out)
}
```

#### Data cleaning

```{r}
claims_clean <- claims_raw %>%
  parse_data()

claims <- claims_clean %>%
  nlp_fn()
```


#### Splitting the data

```{r}
set.seed(102722)
partitions <- claims %>% initial_split(prop = 0.8)

test_dtm <- testing(partitions) %>%
  select(-.id, -bclass)
test_labels <- testing(partitions) %>%
  select(.id, bclass)

train_dtm <- training(partitions) %>%
  select(-.id, -bclass)
train_labels <- training(partitions) %>%
  select(.id, bclass)

proj_out <- projection_fn(.dtm = train_dtm, .prop = 0.7)
train_dtm_projected <- proj_out$data

# number of components used
proj_out$n_pc
```

#### Projection

```{r}
train <- train_labels %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(train_dtm_projected)

x_train <- train %>% select(-bclass) %>% as.matrix()
y_train <- train_labels %>% pull(bclass)
```


## Logistic Regression

#### Storing predictors and response

```{r}
fit_reg <- glmnet(x = x_train, 
                 y = y_train, 
                 family = 'binomial',
                 alpha = alpha_enet)

set.seed(102722)
cvout <- cv.glmnet(x = x_train, 
                   y = y_train, 
                   family = 'binomial',
                   alpha = alpha_enet)

lambda_opt <- cvout$lambda.min

cvout
```

#### Prediction

```{r}
# project test data onto PCs
test_dtm_projected <- reproject_fn(.dtm = test_dtm, proj_out)

# coerce to matrix
x_test <- as.matrix(test_dtm_projected)

# compute predicted probabilities
preds <- predict(fit_reg, 
                 s = lambda_opt, 
                 newx = x_test,
                 type = 'response')

# store predictions in a data frame with true labels
pred_df <- test_labels %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(pred = as.numeric(preds)) %>%
  mutate(bclass.pred = factor(pred > 0.5, 
                              labels = levels(bclass)))

# define classification metric panel 
panel <- metric_set(sensitivity, 
                    specificity, 
                    accuracy, 
                    roc_auc)

# compute test set accuracy
pred_df %>% panel(truth = bclass, 
                  estimate = bclass.pred, 
                  pred, 
                  event_level = 'second')
```

#=============================================================
#### function to parse html and clean text including headers

```{r}
parse_fn_1 <- function(.html){
  read_html(.html) %>%
    html_elements('p, h1, h2, h3, h4, h5, h6') %>%
    html_text2() %>%
    str_c(collapse = ' ') %>%
    rm_url() %>%
    rm_email() %>%
    str_remove_all('\'') %>%
    str_replace_all(paste(c('\n', 
                            '[[:punct:]]', 
                            'nbsp', 
                            '[[:digit:]]', 
                            '[[:symbol:]]'),
                          collapse = '|'), ' ') %>%
    str_replace_all("([a-z])([A-Z])", "\\1 \\2") %>%
    tolower() %>%
    str_replace_all("\\s+", " ")
}
```

#### function to apply to claims data

```{r}
parse_data_1 <- function(.df){
  out <- .df %>%
    filter(str_detect(text_tmp, '<!')) %>%
    rowwise() %>%
    mutate(text_clean = parse_fn_1(text_tmp)) %>%
    unnest(text_clean) 
  return(out)
}

nlp_fn_1 <- function(parse_data_1.out){
  out <- parse_data_1.out %>% 
    unnest_tokens(output = token, 
                  input = text_clean,  # Use the parsed paragraphs + headers
                  token = 'words',
                  stopwords = str_remove_all(stop_words$word, 
                                             '[[:punct:]]')) %>%
    mutate(token.lem = lemmatize_words(token)) %>%
    filter(str_length(token.lem) > 2) %>%
    count(.id, bclass, token.lem, name = 'n') %>%
    bind_tf_idf(term = token.lem, 
                document = .id,
                n = n) %>%
    pivot_wider(id_cols = c('.id', 'bclass'),
                names_from = 'token.lem',
                values_from = 'tf_idf',
                values_fill = 0)
  return(out)
}
```

#### Data cleaning

```{r}
load('data/claims-raw.RData')

claims_clean_1 <- claims_raw %>%
  parse_data_1()

claims_df <- claims_clean_1 %>%
  nlp_fn_1()
```

#### Splitting the data

```{r}
set.seed(102722)
partitions_1 <- claims_df %>% initial_split(prop = 0.8)

test_dtm_1 <- testing(partitions_1) %>%
  select(-.id, -bclass)
test_labels_1 <- testing(partitions_1) %>%
  select(.id, bclass)

train_dtm_1 <- training(partitions_1) %>%
  select(-.id, -bclass)
train_labels_1 <- training(partitions_1) %>%
  select(.id, bclass)
```

#### Projection

```{r}
proj_out_1 <- projection_fn(.dtm = train_dtm_1, .prop = 0.7)
train_dtm_projected_1 <- proj_out_1$data

# number of components used
proj_out_1$n_pc
```

## Logistic Regression w headers

#### Storing predictors and response

```{r}
train_1 <- train_labels_1 %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(train_dtm_projected_1)

x_train_1 <- train_1 %>% select(-bclass) %>% as.matrix()
y_train_1 <- train_labels_1 %>% pull(bclass)
```


#### Fitting the model

```{r}
alpha_enet <- 0.3
fit_reg_hdrs <- glmnet(x = x_train_1, 
                 y = y_train_1, 
                 family = 'binomial',
                 alpha = alpha_enet)


set.seed(102722)
cvout_1 <- cv.glmnet(x = x_train_1, 
                   y = y_train_1, 
                   family = 'binomial',
                   alpha = alpha_enet)

lambda_opt_1 <- cvout_1$lambda.min

cvout_1
```


#### Prediction

```{r}
# project test data onto PCs
test_dtm_projected_1 <- reproject_fn(.dtm = test_dtm_1, proj_out_1)

# coerce to matrix
x_test_1 <- as.matrix(test_dtm_projected_1)

# compute predicted probabilities
preds_hdrs <- predict(fit_reg_hdrs, 
                 s = lambda_opt_1, 
                 newx = x_test_1,
                 type = 'response')

# store predictions in a data frame with true labels
pred_df_hdrs <- test_labels_1 %>%
  transmute(bclass = factor(bclass)) %>%
  bind_cols(pred = as.numeric(preds_hdrs)) %>%
  mutate(bclass.pred = factor(pred > 0.5, 
                              labels = levels(bclass)))

# define classification metric panel 
panel <- metric_set(sensitivity, 
                    specificity, 
                    accuracy, 
                    roc_auc)

# compute test set accuracy
pred_df_hdrs %>% panel(truth = bclass, 
                  estimate = bclass.pred, 
                  pred, 
                  event_level = 'second')
```


## Write up notes

1. Augment the HTML scraping strategy so that header information is captured in addition to paragraph content. 

- Modifying the function that parses the data to include header information with the paragraphs (concatenate headers into text_clean column)

2. Are binary class predictions improved using logistic principal component regression?

**Results from analysis of only paragraphs (without headers):**
Components: 153
-------------------
Call:  cv.glmnet(x = x_train, y = y_train, family = "binomial", alpha = alpha_enet) 

Measure: Binomial Deviance 

Lambda        Index Measure     SE        Nonzero
min 0.0171    32    1.07        0.0308     113
1se 0.0360    24    1.10        0.0191      95
--------------------

sensitivity	  binary	0.8514		
specificity	  binary	0.7399		
accuracy	    binary	0.8025		
roc_auc	      binary	0.8563

**Results from analysis with headers:**
Components: 211
---------------------
Call:  cv.glmnet(x = x_train_1, y = y_train_1, family = "binomial", alpha = alpha_enet) 
Measure: Binomial Deviance 

Lambda        Index Measure     SE        Nonzero
min 0.0164    32    1.13        0.0401     145
1se 0.0314    25    1.16        0.0348     124
---------------------

sensitivity	  binary	0.8089		
specificity	  binary	0.7692		
accuracy	    binary	0.7905		
roc_auc	      binary	0.8764


It appears that including header information did not improve accuracy measures. 
Manually looking at a few entries of the header information some of it is not relevant to the content on the paragraph ie. features or functions on the website were taken as headers suhc as filter or search tools.

Example 1: (header is italicized)
_find the truth filter by location filter by arrest date search public records powered by personal info check clayton thomas arrest details clayton thomas arrest details arrest information_ name clayton thomas location memphis tennessee age years processing date booking charge an arrest does not mean that the individual has been convicted of the alleged violation individuals on this website are innocent until proven guilty by a court of law all information related to charges and arrest or booking is obtained through public domain and in accordance with the freedom of information act....

- While not all of the header information is relevant to the paragraph contents some of it is still related.

Example 2:
_family login_ national obituary search wayne slim straseske obituary click on the item you would like to print obituary guestbook all share this obituary resources arrangements made by koepsell murray funeral cremation services beaver dam n n crystal lake road beaver dam wi...

- The header doesn't really seem to provide meaningful information to the contents of the paragraph. 
