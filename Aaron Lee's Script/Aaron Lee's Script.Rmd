---
title: "Aaron Lee's script"
author: "Aaron Lee (3410388)"
date: "2023-11-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load Libraries and Data

```{r, message=FALSE, echo=FALSE}
require(tidyverse)
require(keras)
require(tensorflow)
source('preprocessing.R')

# Load data
load('claims-raw.RData')
load('claims-test.RData')
```

## Preprocess Data

```{r}
# Apply preprocessing pipeline to training data
claims_clean <- claims_raw %>%
  parse_data()

# Apply preprocessing pipeline to test data
clean_df <- claims_test %>%
  parse_data() %>%
  select(.id, text_clean)
```

```{r}
save(claims_clean, file = "claims-clean.RData")
```

## Binary Classification Model

```{r}
library(tidyverse)
library(tidymodels)
library(keras)
library(tensorflow)

# Load cleaned data
load('claims-clean.RData')

# Partition data
set.seed(123)
partitions <- claims_clean %>%
  initial_split(prop = 0.8)

# Extract training text and labels
train_text <- training(partitions) %>%
  pull(text_clean)
train_labels <- training(partitions) %>%
  pull(bclass) %>%
  as.numeric() - 1

# If having library conflicts
install.packages("keras", type = "source")
library(keras)
install_keras()
```


```{r}
# Create preprocessing layer
preprocess_layer <- layer_text_vectorization(
  standardize = NULL,
  split = 'whitespace',
  ngrams = NULL,
  max_tokens = NULL,
  output_mode = 'tf_idf'
)

preprocess_layer %>% adapt(train_text)

# Define NN architecture for binary classification
binary_model <- keras_model_sequential() %>%
  preprocess_layer() %>%
  layer_dropout(0.2) %>%
  layer_dense(units = 25) %>%
  layer_dropout(0.2) %>%
  layer_dense(1) %>%
  layer_activation(activation = 'sigmoid')

summary(binary_model)

# Configure for training
binary_model %>% compile(
  loss = 'binary_crossentropy',
  optimizer = 'adam',
  metrics = 'binary_accuracy'
)

# Train binary model
history_binary <- binary_model %>%
  fit(train_text, 
      train_labels,
      validation_split = 0.3,
      epochs = 5)

# Save binary model
save_model_tf(binary_model, "results/binary_model")

# Predictions for binary model
preds_binary <- predict(binary_model, clean_df$text_clean) %>%
  as.numeric()

# Convert to binary labels
class_labels_binary <- claims_raw %>% pull(bclass) %>% levels()
pred_classes_binary <- factor(preds_binary > 0.5, labels = class_labels_binary)

```

## Multi-Class Classification Model

```{r}
# Define NN architecture for multi-class classification
multi_model <- keras_model_sequential() %>%
  preprocess_layer() %>%
  layer_dropout(0.2) %>%
  layer_dense(units = 25) %>%
  layer_dropout(0.2) %>%
  layer_dense(length(class_labels_binary), activation = 'softmax')

summary(multi_model)

# Configure for training
multi_model %>% compile(
  loss = 'sparse_categorical_crossentropy',
  optimizer = 'adam',
  metrics = 'accuracy'
)

# Convert multi-class labels to numeric
train_labels_multi <- training(partitions) %>%
  pull(bclass) %>%
  as.factor() %>%
  as.numeric() - 1

# Train multi-class model
history_multi <- multi_model %>%
  fit(train_text, 
      train_labels_multi,
      validation_split = 0.3,
      epochs = 5)

# Save multi-class model
save_model_tf(multi_model, "results/multi_model")

# Predictions for multi-class model
preds_multi <- predict(multi_model, clean_df$text_clean)
class_labels_multi <- claims_raw %>% pull(bclass) %>% levels()
pred_classes_multi <- factor(apply(preds_multi, 1, which.max), labels = class_labels_multi)
```


## Export Predictions

```{r}
# Create and save binary predictions
pred_df_binary <- clean_df %>%
  bind_cols(bclass.pred = pred_classes_binary) %>%
  select(.id, bclass.pred)

save(pred_df_binary, file = 'results/binary_preds.RData')

# Create and save multi-class predictions
pred_df_multi <- clean_df %>%
  bind_cols(mclass.pred = pred_classes_multi) %>%
  select(.id, mclass.pred)

save(pred_df_multi, file = 'results/multi_preds.RData')

```

